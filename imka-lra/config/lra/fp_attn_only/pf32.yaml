checkpoint:
  best_checkpoint_metric: accuracy
  maximize_best_checkpoint_metric: true
  no_save: false
  restore_file: ???
  save_dir: ???
common:
  log_format: simple
  log_interval: 100
  seed: 0
  tensorboard_logdir: ???
criterion:
  _name: lra_cross_entropy
dataset:
  batch_size: 256
lr_scheduler:
  _name: linear_decay
  warmup_updates: 4000
  warmup_init_lr: 1.0e-07
model:
  _name: transformer_lra_pf32
  activation_dropout: 0.0
  activation_fn: silu
  attention_dropout: 0.0
  classifier_out_dim: 256
  dropout: 0.0
  encoder:
    attention_heads: 8
    embed_dim: 128
    ffn_embed_dim: 128
    layers: 1
    normalize_before: true
    xformers_att_config: '{''name'': ''favor'', ''dim_features'':256, ''input_features'':16, ''iter_before_redraw'': 1000, ''device'':''cuda''}'
  input_type: image
  layer_type: transformer
  max_positions: 1024
  norm_type: layernorm
  sen_rep_type: mp
optimization:
  clip_norm: 1
  lr:
  - 0.0001
  max_epoch: 10000000
  max_update: 100000
  sentence_avg: true
optimizer:
  _name: adam
  adam_betas: (0.9,0.999)
  adam_eps: 1.0e-06
  weight_decay: 0.01
task:
  _name: lra-image
  data: ???
  num_classes: 2
  pixel_normalization: '[0.5, 0.5]'
